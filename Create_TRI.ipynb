{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, gdal\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "from math import pi\n",
    "\n",
    "from skimage.morphology import square,diamond,ball, disk\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "from scipy.ndimage.filters import generic_filter\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat, binary_erosion, remove_small_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of DSMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dsm = '../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm/'\n",
    "dsms = [os.path.join(loc_dsm,f) for f in os.listdir(loc_dsm) if f.endswith(\".tif\")]\n",
    "\n",
    "#overviews = Parallel(n_jobs=10, verbose=30)(delayed(developOverviews)(dsm) for dsm in dsms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Roads in EPC Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(\"../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm/EPC_DSM80cm_2019.vrt\") as src:\n",
    "    full_bounds = src.bounds\n",
    "    full_bb = box(full_bounds.left,full_bounds.bottom, full_bounds.right, full_bounds.top)\n",
    "    \n",
    "\n",
    "if \"routes_pc\" not in globals():\n",
    "    osm_lines_loc = \"../OtherData/arizona-latest-20200507.shp/gis_osm_roads_free_1.shp\"\n",
    "    routes = gpd.read_file(osm_lines_loc).to_crs('epsg:2868')\n",
    "    routes_pc = gpd.clip(routes, full_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't need this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate TRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def windowTRI(a):\n",
    "    shp = a.shape\n",
    "    mm = round(a.shape[0]/2)\n",
    "    centralVal = a[mm]\n",
    "    diff = np.absolute(a-centralVal)\n",
    "    average = np.mean(diff)\n",
    "    total_size = shp[0]\n",
    "    tri = average*(total_size)/(total_size-1)\n",
    "    return tri\n",
    "\n",
    "def computeTRI(arr, winsize):\n",
    "    if winsize % 2 == 0:\n",
    "        raise ValueError(\"Bad window size. Must be odd number\")\n",
    "    out = generic_filter(arr, windowTRI, footprint=square(winsize), mode='mirror', cval=0)\n",
    "    return out\n",
    "\n",
    "#tri_test = computeTRI(test_array, 5)\n",
    "#tri_test[2,2]\n",
    "def createTRIRasters(infile, out_loc, window_size=5, overwrite=True):\n",
    "    ofile = os.path.join(out_loc, os.path.basename(infile).replace(\".tif\",\"_TRI.tif\"))\n",
    "    if os.path.exists(ofile) and overwrite == False:\n",
    "        return ofile\n",
    "    \n",
    "    with rio.open(infile) as ras:\n",
    "        msk = ras.read_masks(1)\n",
    "        dsm_array = ras.read(1)\n",
    "        dsm_array[msk==0] = np.NaN\n",
    "        kwargs = ras.profile\n",
    "\n",
    "    tri = computeTRI(dsm_array, window_size)\n",
    "    tri[msk==0] = np.NaN\n",
    "    kwargs.update(tiled=True, compress='lzw')\n",
    "    with rio.open(ofile, 'w', **kwargs) as oras:\n",
    "        oras.write(tri, 1)                 \n",
    "    \n",
    "    return ofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_loc = \"../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm_TRI/\"\n",
    "os.makedirs(tri_loc, exist_ok=True)\n",
    "tri_files = Parallel(n_jobs=10, verbose=5)(delayed(createTRIRasters)(dsm, tri_loc, window_size=5, overwrite=False) for dsm in dsms)\n",
    "gdalbuildvrt_cmd = f\"\"\"gdalbuildvrt {os.path.join(tri_loc,'EPC_DSM80cmTRI_2019.vrt')} {tri_loc}/*.tif\"\"\"\n",
    "os.system(gdalbuildvrt_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Slope for 30m DEMs from NED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_tifs = [os.path.join(\"../OtherData/elevation_NED30M/\", os.path.basename(f)) for f in os.listdir(\"../OtherData/elevation_NED30M/\") if f.endswith(\".tif\")]\n",
    "ned_slope_dir = \"../OtherData/elevation_NED30M_Slope\"\n",
    "os.makedirs(ned_slope_dir, exist_ok=True)\n",
    "slopes = Parallel(n_jobs=4, verbose=5)(delayed(calcSlopes)(ned_tif, ned_slope_dir, overwrite=False) for ned_tif in ned_tifs)\n",
    "gdalbuildvrt_cmd = f\"\"\"gdalbuildvrt {os.path.join(ned_slope_dir,'NED30m_Slope.vrt')} {' '.join(slopes)}\"\"\"\n",
    "os.system(gdalbuildvrt_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Low TRI mean flatter, but could be a building rooftop or ground\n",
    "2. For building rooftops, they are characterized by high variance of TRI across the larger radius radius. 300ft would be maxium radial size of building (600 ft span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def windowStd(a):\n",
    "    return np.std(a)\n",
    "\n",
    "def getStdDevWindow(arr, winsize):\n",
    "    out = generic_filter(arr, windowStd, footprint=diamond(winsize), mode='mirror')\n",
    "    return out\n",
    "\n",
    "loc_tri = '../EPCExtent_30cm/Elevation_80cmNPS/DSM_TRI'\n",
    "tris = [os.path.join(loc_tri,f) for f in os.listdir(loc_tri) if f.endswith(\".tif\")]\n",
    "\n",
    "loc_triStdDev = '../EPCExtent_30cm/Elevation_80cmNPS/DSM_TRIStdDev'\n",
    "os.makedirs(loc_triStdDev, exist_ok=True)\n",
    "\n",
    "overwrite = True\n",
    "\n",
    "count = 0\n",
    "window_sizes = [30]\n",
    "pairs = {}\n",
    "for tri in tris:\n",
    "    for window_size in window_sizes:\n",
    "        ofile = os.path.join(loc_triStdDev, os.path.basename(tri).replace(\"_DSMTRI.tif\", f\"_DSMTRIStdDev{window_size}.tif\"))\n",
    "        pairs[tri] = ofile\n",
    "        \n",
    "def calcStdDevWindow(tri, ofile, overwrite=False):\n",
    "    global count\n",
    "    s0 = datetime.now()\n",
    "    count += 1\n",
    "    if os.path.exists(ofile) and not overwrite:\n",
    "        return 0\n",
    "    if \"E1020_N430\" not in ofile:# and \"E0920_N470\" not in ofile:\n",
    "        return\n",
    "    \n",
    "    window_size = os.path.basename(ofile).split(\"_DSMTRIStDev\")[1].split(\".\")[0]\n",
    "    \n",
    "    with rio.open(tri) as ras:\n",
    "        msk = ras.read_masks(1)\n",
    "        tri_array = ras.read(1)\n",
    "        tri_array[msk==0] = np.NaN\n",
    "        kwargs = ras.profile\n",
    "\n",
    "    stddev_TRI = getStdDevWindow(tri_array, window_size)\n",
    "\n",
    "    with rio.open(ofile, 'w', **kwargs) as oras:\n",
    "        oras.write(stddev_TRI, 1)                 \n",
    "    s1 = datetime.now()\n",
    "    elapsed = s1-s0\n",
    "    print(f\"\\t{elapsed}\")\n",
    "    print(f\"{count} - Finished with {ofile}\")\n",
    "\n",
    "    return elapsed\n",
    "        \n",
    "time_lapse = Parallel(n_jobs=6)(delayed(calcStdDevWindow)(k, v) for k,v in pairs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_erosion, remove_small_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developOverviews(file):\n",
    "    os.system(f\"gdalinfo -mm {file}\")\n",
    "    os.system(f\"gdaladdo -clean {file}\")\n",
    "    os.system(f\"gdaladdo -r average -ro --config COMPRESS_OVERVIEW LZW -minsize 8 {file}\")\n",
    "    \n",
    "def fillTRIHoles(tri, odir, routes_pc, threshold=1, disk_size=2, overwrite=False):\n",
    "    ofile = os.path.join(odir, os.path.basename(tri).replace(\".tif\", f\"_FillT{threshold}DS{disk_size}.tif\"))\n",
    "    if os.path.exists(ofile) and not overwrite:\n",
    "        return ofile\n",
    "    \n",
    "    with rio.open(tri) as ras:\n",
    "        tri_data = ras.read(1)\n",
    "        mask = ras.read_masks(1)\n",
    "        kwargs = ras.profile\n",
    "        rbs= ras.bounds\n",
    "        bb= box(rbs.left,rbs.bottom, rbs.right, rbs.top)\n",
    "        res = ras.res[0]\n",
    "        \n",
    "    #secondPercentile = np.percentile(test[mask!=0],2)\n",
    "    #ninetyeightPercentile = np.percentile(test[mask!=0],98)\n",
    "    #edge_limit = ninetyeightPercentile-((ninetyeightPercentile-secondPercentile)/2)\n",
    "    #clip and buffer by 10 feet\n",
    "    routes_local = gpd.clip(routes_pc,bb).buffer(10/res)\n",
    "    \n",
    "    # threshold edges to yes or no\n",
    "    edges = np.where(tri_data <= threshold, 0, 1).astype(np.uint8)\n",
    "    \n",
    "    #close \n",
    "    edges = closing(edges, disk(disk_size))\n",
    "    \n",
    "    # fill regions completely enclosed\n",
    "    filled = ndi.binary_fill_holes(edges)\n",
    "    # Erode filled holes\n",
    "    filled = binary_erosion(filled, selem=square(5))\n",
    "    #burn in roads as 0 TRI\n",
    "    if len(routes_local)!=0:\n",
    "        geom = routes_local.geometry.to_list()\n",
    "        roads_raster = rasterize(geom, out_shape=(kwargs['width'], kwargs['height']), all_touched=True, transform=kwargs['transform'], fill=1, default_value=0)\n",
    "        filled = np.minimum(filled,roads_raster)\n",
    "    \n",
    "    # remove small regions of isolated edges. Regions smaller than the smallest window used in DTM generation do not need to exist\n",
    "    #filled = remove_small_objects(filled.astype(bool), min_size=pi*(13*13), connectivity=0)\n",
    "\n",
    "    edges[mask==0] = 1\n",
    "\n",
    "    kwargs.update(dtype=np.uint8, nodata=255)\n",
    "    with rio.open(ofile, 'w', **kwargs) as dst:\n",
    "        dst.write(filled.astype(np.uint8),1)\n",
    "    #with rio.open(\"./roads.tif\", 'w', **kwargs) as dst:\n",
    "    #    dst.write(roads_raster.astype(np.uint8), 1)\n",
    "        \n",
    "    developOverviews(ofile)\n",
    "    \n",
    "    return ofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fillTRIHoles(ofile, \"./\", routes_pc, threshold=1, disk_size=1, overwrite=True)\n",
    "fillTRIHoles('../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm_TRI/E0980_N470_DSM80cm_TRI.tif', \"./\", routes_pc, threshold=1, disk_size=0, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAreaRaster(tri_fill, out_loc, overwrite=False):\n",
    "    ofile = os.path.join(out_loc, os.path.basename(tri_fill).replace(\".tif\",\"_area.tif\"))\n",
    "    if os.path.exists(ofile) and overwrite == False:\n",
    "        return ofile\n",
    "    with rio.open(tri_fill) as src:\n",
    "        array = src.read(1)\n",
    "    labels, lcount = label(array, return_num=True)\n",
    "    props = regionprops(labels, array, properties=['label','area'])\n",
    "    value_map_area = {}\n",
    "    for i, r in enumerate(props):\n",
    "        value_map_area[r.label] = r.area\n",
    "    value_map_area[0] = 0\n",
    "    area_array = np.vectorize(value_map_area.__getitem__)(labels)\n",
    "    kwargs.update(dtype=np.uint32)\n",
    "    with rio.open(ofile, 'w', **kwargs) as dst:\n",
    "        dst.write(area_array.astype(np.uint32),1)\n",
    "    return ofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_loc = '../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm_TRI'\n",
    "triFilled_loc = '../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm_TRI_filled'\n",
    "os.makedirs(triFilled_loc, exist_ok=True)\n",
    "dsm_tri = [os.path.join(tri_loc,f) for f in os.listdir(tri_loc) if f.endswith(\".tif\")]\n",
    "# TRI value is the mean of the difference of a cell and the cells surrounding it\n",
    "#tri_filled = Parallel(n_jobs=10, verbose=5)(delayed(fillTRIHoles)(tri_file, triFilled_loc, routes_pc, threshold=1, disk_size=0, overwrite=False) for tri_file in dsm_tri)\n",
    "filledVRT_cmd = \"\"\"gdalbuildvrt ../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm_TRI_filled/TRI80cmFilled_2019.vrt ../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm_TRI_filled/*.tif\"\"\"\n",
    "os.system(filledVRT_cmd)\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_loc = \"../EPCExtent_30cm/Elevation_80cmNPS/DSM80cm_TRI_filled_Area\"\n",
    "os.makedirs(area_loc, exist_ok==True)\n",
    "#area_files = Parallel(n_jobs=10, verbose=5)(delayed(buildAreaRaster)(tf, area_loc, overwrite=False) for tf in tri_filled)\n",
    "areaVRT_cmd = f\"\"\"gdalbuildvrt {area_loc}/TRIFilledArea80cm_2019.vrt {area_loc}/*.tif\"\"\"\n",
    "os.system(filledVRT_cmd)\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________../EPCExtent_30cm/________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# Watershed Segmentation of HAG\n",
    "https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_watershed.html#sphx-glr-auto-examples-segmentation-plot-watershed-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(hag, out_dir, threshold=4, overwrite=False):\n",
    "    ofile = os.path.join(out_loc, os.path.basename(hag).replace(\".tif\",\"_distance.tif\"))\n",
    "    \n",
    "    if os.path.exists(ofile) and overwrite==False:\n",
    "        return ofile\n",
    "    \n",
    "    with rio.open(hag) as src:\n",
    "        kwargs = src.profile\n",
    "        hag_a = src.read(1)\n",
    "    hag_a = np.where(hag_a>=threshold,1,0)\n",
    "    \n",
    "    #calculate euclidean distance to ground\n",
    "    distance = ndi.distance_transform_edt(hag_a)\n",
    "    distance = np.ceil(distance)\n",
    "    \n",
    "    kwargs.update(dtype=np.int32)\n",
    "    with rio.open(ofile, 'w', **kwargs) as dst:\n",
    "        dst.write(distance.astype(np.int32),1)\n",
    "        \n",
    "    return ofile\n",
    "\n",
    "dist_loc = \"../EPCExtent_30cm/Elevation_80cmNPS/HAG_NED_80cm_DTG\"\n",
    "os.makedirs(dist_loc, exist_ok==True)\n",
    "distance_files = Parallel(n_jobs=12, verbose=20)(delayed(calculateDistance)(file, dist_loc, threshold=4, overwrite=False) for file in hag_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from datetime import datetime\n",
    "from rasterio.plot import show\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "t1 = datetime.now()\n",
    "hag = '../EPCExtent_30cm/Elevation_80cmNPS/HAG_NED_80cm/E1000_N450_DSM80cm_HAG.tif'\n",
    "\n",
    "with rio.open(hag) as src:\n",
    "    kwargs = src.profile\n",
    "    hag_a = src.read(1)\n",
    "    hag_a = np.where(hag_a>=4,1,0)\n",
    "    res = src.res[0]\n",
    "    \n",
    "# Now we want to separate the two objects in image\n",
    "# Generate the markers as local maxima of the distance to the background\n",
    "distance = ndi.distance_transform_edt(hag_a)\n",
    "local_maxi = peak_local_max(distance, indices=False, labels=hag_a, footprint=np.ones((1, 1)) )\n",
    "markers = ndi.label(local_maxi)[0]\n",
    "\n",
    "labels = watershed(-distance, markers, mask=hag_a, compactness=100)\n",
    "\n",
    "props = regionprops(labels, labels)#, properties=['label','area'])\n",
    "value_map_area = {}\n",
    "for i, r in enumerate(props):\n",
    "    value_map_area[r.label] = r.area\n",
    "value_map_area[0] = 0\n",
    "area_array = np.vectorize(value_map_area.__getitem__)(labels)\n",
    "areaft_array = area_array*(res**2)\n",
    "    \n",
    "kwargs.update(dtype=np.int32)\n",
    "with rio.open(\"area.tif\", 'w', **kwargs) as dst:\n",
    "    dst.write(areaft_array.astype(np.int32),1)\n",
    "    \n",
    "    \n",
    "t2=datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdal_extract_pipeline = \"\"\"[\n",
    "    %s,\n",
    "    {\n",
    "      \"type\":\"filters.colorization\",\n",
    "      \"raster\":%s,\n",
    "      \"dimension\":\"DTG\"\n",
    "    },\n",
    "    \"coloured-striped.las\"\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
