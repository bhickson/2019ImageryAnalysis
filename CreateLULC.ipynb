{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LULC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext chime\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import chime\n",
    "\n",
    "import rasterio as rio\n",
    "import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from skimage.morphology import binary_closing, binary_opening, square, remove_small_holes, disk, square\n",
    "\n",
    "from skimage.filters.rank import modal, mean_bilateral\n",
    "from datetime import datetime, timedelta, time\n",
    "from time import sleep\n",
    "import nbimporter\n",
    "#from KeyFunctions import *\n",
    "import chime\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def throttleProcessors(workDayStart, workDayEnd):\n",
    "    startPause = time(*(map(int, workDayStart.split(':'))))\n",
    "    endPause = time(*(map(int, workDayEnd.split(':'))))\n",
    "    nowTime = datetime.today().time()\n",
    "    if nowTime < endPause or nowTime > startPause:\n",
    "        print(f\"Current time is {nowTime}. Setting processor/thread use to 4\")\n",
    "        return 4\n",
    "    else:\n",
    "        return 8\n",
    "\n",
    "def wait_start(workDayStart=\"8:30\", workDayEnd=\"18:00\", force=False):\n",
    "    startPause = time(*(map(int, workDayStart.split(':'))))\n",
    "    endPause = time(*(map(int, workDayEnd.split(':'))))\n",
    "    nowTime = datetime.today().time()\n",
    "    if nowTime < endPause and nowTime > startPause and datetime.today().isoweekday() <= 5 and not force:\n",
    "        waitTimeSeconds = datetime.combine(datetime.today(), endPause) - datetime.combine(datetime.today(), nowTime)\n",
    "    else:\n",
    "        waitTimeSeconds = False\n",
    "    return waitTimeSeconds\n",
    "\n",
    "\n",
    "def createClassifiedRaster(classification_model, ortho_file, classifiedFiles_loc, overwrite=False):\n",
    "    start = datetime.now()\n",
    "    day = datetime.now().strftime(\"%Y%m%d\")\n",
    "    daynum = 1\n",
    "    output_image = os.path.join(classifiedFiles_loc, os.path.basename(ortho_file).replace(\".tif\", f\"_classLGBNewishGBLM.tif\"))#_{day}-{daynum}.tif\"))\n",
    "    if os.path.exists(output_image) and not overwrite:\n",
    "        print(\"File exists\")\n",
    "        return output_image\n",
    "    try:\n",
    "        with rio.open(ortho_file) as src:\n",
    "            kwargs = src.profile\n",
    "            kwargs.update(\n",
    "                dtype= rio.uint8,\n",
    "                count= 1,\n",
    "            )\n",
    "\n",
    "            data = src.read()\n",
    "            descs = list(src.descriptions)\n",
    "    except:\n",
    "        print(f\"ERROR: Unable to open {os.path.basename(ortho_file)}. Skipping\")\n",
    "        return None\n",
    "    \n",
    "    kwargs.update(\n",
    "        dtype= rio.uint8,\n",
    "        count= 1,\n",
    "    )\n",
    "    \n",
    "    feature_names = classification_model.feature_name_\n",
    "\n",
    "    bands = {desc:data[ib] for ib, desc in enumerate(descs)}\n",
    "    \n",
    "    #This is a training dataset not created with the others, but may be in the classifier. Create and add\n",
    "    if \"RGBNmean\" in feature_names:\n",
    "        print(\"Adding RGBNmean\")\n",
    "        rgbnMean = np.nanmean(data[:4], axis=0).astype(data.dtype)\n",
    "        bands[\"RGBNmean\"] = rgbnMean\n",
    "\n",
    "    features = {fn:bands[fn] for fn in feature_names}# if fn in descs}\n",
    "    \n",
    "    featureArrays = list(features.values())\n",
    "            \n",
    "    trainingFeatures = np.stack(featureArrays)\n",
    "\n",
    "    #print(\"Input Data shape\", data.shape)\n",
    "    \n",
    "    # read the image into the proper format, adding indices if necessary\n",
    "    img_swp = np.moveaxis(trainingFeatures, 0, -1)\n",
    "    img_flat = img_swp.reshape(-1, img_swp.shape[-1])\n",
    "    \n",
    "    #flatten bands along axis\n",
    "    img_flat = img_swp.reshape(-1, img_swp.shape[-1])\n",
    "    \n",
    "    # remove no data values, store the indices for later use\n",
    "    # a later cell makes the assumption that all bands have identical no-data value arrangements\n",
    "    m = np.ma.masked_invalid(img_flat)\n",
    "    to_predict = img_flat[~m.mask].reshape(-1, img_flat.shape[-1])\n",
    "    \n",
    "    # predict\n",
    "    #print(\"Beginning prediction...\", datetime.now())\n",
    "    img_preds = classification_model.predict(to_predict)\n",
    "    \n",
    "    # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity)\n",
    "    # resize to the original image dimensions\n",
    "    output = np.zeros(img_flat.shape[0])\n",
    "    output[~m.mask[:,0]] = img_preds.flatten()\n",
    "    output = output.reshape(*img_swp.shape[:-1])\n",
    "    \n",
    "    # create our final mask\n",
    "    mask = (~m.mask[:,0]).reshape(*img_swp.shape[:-1])\n",
    "    \n",
    "    with rio.open(output_image, 'w', **kwargs) as dst: \n",
    "\n",
    "        colors = {\n",
    "            1: (12,42,235, 255),\n",
    "            2: (41, 210, 219,255),\n",
    "            3: (255, 214, 117, 255),\n",
    "            4: (171, 224, 85, 255),\n",
    "            5: (12, 100, 1, 255),\n",
    "            6: (0, 192, 32, 255),\n",
    "            7: (62, 62, 62, 255),\n",
    "            8: (160, 160, 160, 255),\n",
    "            9: (160, 37, 6, 255)\n",
    "        }\n",
    "        \n",
    "        # write to the final file\n",
    "        dst.write(output.astype(rio.uint8), 1)\n",
    "        #dst.write_mask(mask)\n",
    "        \n",
    "        dst.write_colormap(1, colors)\n",
    "        \n",
    "    return output_image\n",
    "\n",
    "    print(f\"Classified to {os.path.abspath(output_image)}. \\nClassification took {datetime.now()-start}\")\n",
    "    %chime\n",
    "    \n",
    "    \n",
    "def classifyTiles(df, forceStart=False, overwrite=False):\n",
    "    print(f\"\\n\\nStarting processing for {len(df)} tiles\\n\")\n",
    "    for i, r in df.iterrows():\n",
    "        #bestlgbm_model.set_params(n_jobs=throttleProcessors(\"8:30\", \"18:00\"))\n",
    "        waitTime = wait_start(force=forceStart)\n",
    "        if waitTime:\n",
    "            buildVRT(classifiedFiles_loc, \"EPC_30cmOrthoSegmented_Classified.vrt\")\n",
    "            pause_until = datetime.now() + waitTime\n",
    "            print(f\"waiting {timedelta(seconds=waitTime.seconds)} until {pause_until.strftime('%H:%m')}\")\n",
    "            sleep(waitTime.seconds)\n",
    "            \n",
    "        print(f\"Starting {r.path}_{r.row} @ {datetime.now()}\")\n",
    "        result = createClassifiedRaster(classification_model=bestlgbm_model,\n",
    "                                        ortho_file=r.OrthoFile,\n",
    "                                        classifiedFiles_loc=classifiedFiles_loc,\n",
    "                                        overwrite=overwrite)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BenJames\\anaconda3\\envs\\geospatial\\lib\\site-packages\\geopandas\\geodataframe.py:294: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for f in features_lst:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "bestlgbm_model = pickle.load(open(\"./Models/lightGBM_20210614.sav\", 'rb'))\n",
    "\n",
    "classifiedFiles_loc = \"../EPCExtent_30cm/Orthos_Segmented_Classifiedv3\"\n",
    "#propsDir = r\"../EPCExtent_30cm/Orthos_Segmentedv2_properties\"\n",
    "orthosDir = r\"../EPCExtent_30cm/Orthos_Segmentedv3\"\n",
    "os.makedirs(classifiedFiles_loc, exist_ok=True)\n",
    "\n",
    "tindex = gpd.read_file(\"../EPCExtent_30cm/Ortho_5kSubIndex.gpkg\")\n",
    "to_process = gpd.read_file(\"../temp/ToProcess.gpkg\")\n",
    "\n",
    "tindex[\"OrthoFile\"] = tindex.apply(lambda r: findFile(path=r.path, row=r.row, directory=orthosDir), axis=1)\n",
    "#tindex[\"PropsFile\"] = tindex.apply(lambda r: findFile(path=r.path, row=r.row, files=propsDir), axis=1)\n",
    "\n",
    "# ignore tiles which don't have input variables created\n",
    "tindex = tindex[(~pd.isnull(tindex.OrthoFile))]\n",
    "\n",
    "#prioritize central tucson and work out from there\n",
    "tindex[\"centroid\"] = tindex.geometry.centroid\n",
    "central_tile = tindex[(tindex.path == \"W1004789\") & (tindex.row == \"W449850\")]\n",
    "central_point = central_tile.centroid.values[0]\n",
    "\n",
    "tindex[\"DistToCenter\"] = tindex.centroid.apply(lambda c: int(c.distance(central_point)))\n",
    "tindex.sort_values(by=\"DistToCenter\", inplace=True)\n",
    "\n",
    "#filter out files that are completed\n",
    "#lulc_done = glob(\"../EPCExtent_30cm/Orthos_Segmented_Classified/*.tif\")\n",
    "tindex[\"Done\"]= tindex.apply(lambda r: findFile(path=r.path, row=r.row, directory=classifiedFiles_loc),axis=1)\n",
    "#tindex = tindex[pd.isnull(tindex[\"Done\"])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#toProcess = tindex[tindex.geometry.intersects(to_process.unary_union)].reset_index()                                 \n",
    "#classifyTiles(toProcess)\n",
    "#finished()\n",
    "#classifyTiles(tindex)\n",
    "#finished()\n",
    "\n",
    "print(\"\\nFINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tindex[(tindex.path == \"W989789\") & (tindex.row == \"W439850\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting processing for 1 tiles\n",
      "\n",
      "Starting W989789_W439850 @ 2021-06-14 12:28:38.667388\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = classifyTiles(tt, forceStart=True, overwrite=True)\n",
    "finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
