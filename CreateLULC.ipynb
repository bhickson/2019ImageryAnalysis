{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LULC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext chime\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import chime\n",
    "\n",
    "import rasterio as rio\n",
    "import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from skimage.morphology import binary_closing, binary_opening, square, remove_small_holes, disk, square\n",
    "\n",
    "from skimage.filters.rank import modal, mean_bilateral\n",
    "from datetime import datetime, timedelta, time\n",
    "from time import sleep\n",
    "import nbimporter\n",
    "#from KeyFunctions import *\n",
    "import chime\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def throttleProcessors(workDayStart, workDayEnd):\n",
    "    startPause = time(*(map(int, workDayStart.split(':'))))\n",
    "    endPause = time(*(map(int, workDayEnd.split(':'))))\n",
    "    nowTime = datetime.today().time()\n",
    "    if nowTime < endPause or nowTime > startPause:\n",
    "        print(f\"Current time is {nowTime}. Setting processor/thread use to 4\")\n",
    "        return 4\n",
    "    else:\n",
    "        return 8\n",
    "\n",
    "def wait_start(workDayStart=\"8:30\", workDayEnd=\"18:00\", force=False):\n",
    "    startPause = time(*(map(int, workDayStart.split(':'))))\n",
    "    endPause = time(*(map(int, workDayEnd.split(':'))))\n",
    "    nowTime = datetime.today().time()\n",
    "    if nowTime < endPause and nowTime > startPause and datetime.today().isoweekday() <= 5 and not force:\n",
    "        waitTimeSeconds = datetime.combine(datetime.today(), endPause) - datetime.combine(datetime.today(), nowTime)\n",
    "    else:\n",
    "        waitTimeSeconds = False\n",
    "    return waitTimeSeconds\n",
    "\n",
    "\n",
    "def createClassifiedRaster(classification_model, ortho_file, classifiedFiles_loc, binaryClass=None, overwrite=False):\n",
    "    start = datetime.now()\n",
    "    day = datetime.now().strftime(\"%Y%m%d\")\n",
    "    daynum = 1\n",
    "    output_image = os.path.join(classifiedFiles_loc, os.path.basename(ortho_file))#_{day}-{daynum}.tif\"))\n",
    "    if binaryClass:\n",
    "        #print(f\"Setting binary output ({output_image})\")\n",
    "        output_image = output_image.replace(\".tif\", f\"_{binaryClass}BinaryLGBNewishGBLM.tif\")\n",
    "    if os.path.exists(output_image) and not overwrite:\n",
    "        #print(f\"File exists ({output_image})\")\n",
    "        return output_image\n",
    "    try:\n",
    "        with rio.open(ortho_file) as src:\n",
    "            kwargs = src.profile\n",
    "            kwargs.update(\n",
    "                dtype= rio.uint8,\n",
    "                count= 1,\n",
    "            )\n",
    "\n",
    "            data = src.read()\n",
    "            descs = list(src.descriptions)\n",
    "    except:\n",
    "        print(f\"ERROR: Unable to open {os.path.basename(ortho_file)}. Skipping\")\n",
    "        return None\n",
    "    \n",
    "    kwargs.update(\n",
    "        dtype= rio.uint8,\n",
    "        count= 1,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        feature_names = classification_model.feature_name_\n",
    "    except:\n",
    "        feature_names = classification_model.feature_name()\n",
    "    \n",
    "\n",
    "    bands = {desc:data[ib] for ib, desc in enumerate(descs)}\n",
    "    \n",
    "    #This is a training dataset not created with the others, but may be in the classifier. Create and add\n",
    "    if \"RGBNmean\" in feature_names:\n",
    "        #print(\"Adding RGBNmean\")\n",
    "        rgbnMean = np.nanmean(data[:4], axis=0).astype(data.dtype)\n",
    "        bands[\"RGBNmean\"] = rgbnMean\n",
    "\n",
    "    features = {fn:bands[fn] for fn in feature_names}# if fn in descs}\n",
    "    \n",
    "    featureArrays = list(features.values())\n",
    "            \n",
    "    trainingFeatures = np.stack(featureArrays)\n",
    "\n",
    "    #print(\"Input Data shape\", data.shape)\n",
    "    \n",
    "    # read the image into the proper format, adding indices if necessary\n",
    "    img_swp = np.moveaxis(trainingFeatures, 0, -1)\n",
    "    img_flat = img_swp.reshape(-1, img_swp.shape[-1])\n",
    "    \n",
    "    #flatten bands along axis\n",
    "    img_flat = img_swp.reshape(-1, img_swp.shape[-1])\n",
    "    \n",
    "    # remove no data values, store the indices for later use\n",
    "    # a later cell makes the assumption that all bands have identical no-data value arrangements\n",
    "    m = np.ma.masked_invalid(img_flat)\n",
    "    to_predict = img_flat[~m.mask].reshape(-1, img_flat.shape[-1])\n",
    "    #print(\"TO PREDICT SHAPE\", to_predict.shape)\n",
    "    \n",
    "    # predict\n",
    "    #print(\"Beginning prediction...\", datetime.now())\n",
    "    img_preds = classification_model.predict(to_predict)\n",
    "    \n",
    "    # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity)\n",
    "    # resize to the original image dimensions\n",
    "    output = np.zeros(img_flat.shape[0])\n",
    "    output[~m.mask[:,0]] = img_preds.flatten()\n",
    "    output = output.reshape(*img_swp.shape[:-1])\n",
    "    \n",
    "    output = np.rint(output)\n",
    "    # create our final mask\n",
    "    #mask = (~m.mask[:,0]).reshape(*img_swp.shape[:-1])\n",
    "    \n",
    "    with rio.open(output_image, 'w', **kwargs) as dst: \n",
    "\n",
    "        colors = {\n",
    "            1: (12,42,235, 255),\n",
    "            2: (41, 210, 219,255),\n",
    "            3: (255, 214, 117, 255),\n",
    "            4: (171, 224, 85, 255),\n",
    "            5: (12, 100, 1, 255),\n",
    "            6: (0, 192, 32, 255),\n",
    "            7: (62, 62, 62, 255),\n",
    "            8: (160, 160, 160, 255),\n",
    "            9: (160, 37, 6, 255)\n",
    "        }\n",
    "        \n",
    "        # write to the final file\n",
    "        dst.write(output.astype(rio.uint8), 1)\n",
    "        #dst.write_mask(mask)\n",
    "        \n",
    "        dst.write_colormap(1, colors)\n",
    "    \n",
    "    print(f\"Classified to {os.path.abspath(output_image)}. \\nClassification took {datetime.now()-start}\")\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "    %chime\n",
    "    \n",
    "    \n",
    "def classifyTiles(df, forceStart=False, overwrite=False, binaryClass=None):\n",
    "    print(f\"\\n\\nStarting processing for {len(df)} tiles\\n\")\n",
    "    for i, r in df.iterrows():\n",
    "        #bestlgbm_model.set_params(n_jobs=throttleProcessors(\"8:30\", \"18:00\"))\n",
    "        waitTime = wait_start(force=forceStart)\n",
    "        if waitTime:\n",
    "            buildVRT(classifiedFiles_loc, \"EPC_30cmOrthoSegmented_Classified.vrt\")\n",
    "            pause_until = datetime.now() + waitTime\n",
    "            print(f\"waiting {timedelta(seconds=waitTime.seconds)} until {pause_until.strftime('%H:%m')}\")\n",
    "            sleep(waitTime.seconds)\n",
    "            \n",
    "        print(f\"Starting {r.path}_{r.row} @ {datetime.now()}\")\n",
    "        try:\n",
    "            result = createClassifiedRaster(classification_model=bestlgbm_model,\n",
    "                                            ortho_file=r.OrthoFile,\n",
    "                                            classifiedFiles_loc=classifiedFiles_loc,\n",
    "                                            binaryClass = binaryClass,\n",
    "                                            overwrite=overwrite)\n",
    "        except:\n",
    "            print(f\"FAILED FOR {r.OrthoFile}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BenJames\\anaconda3\\envs\\geospatial\\lib\\site-packages\\geopandas\\geodataframe.py:294: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for f in features_lst:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "classifiedFiles_loc = \"../EPCExtent_30cm/Orthos_Segmented_Classifiedv3\"\n",
    "#propsDir = r\"../EPCExtent_30cm/Orthos_Segmentedv2_properties\"\n",
    "orthosDir = r\"../EPCExtent_30cm/Orthos_Segmentedv3\"\n",
    "os.makedirs(classifiedFiles_loc, exist_ok=True)\n",
    "\n",
    "tindex = gpd.read_file(\"../EPCExtent_30cm/Ortho_5kSubIndex.gpkg\")\n",
    "to_process = gpd.read_file(\"../temp/ToProcess.gpkg\")\n",
    "\n",
    "tindex[\"OrthoFile\"] = tindex.apply(lambda r: findFile(path=r.path, row=r.row, directory=orthosDir), axis=1)\n",
    "#tindex[\"PropsFile\"] = tindex.apply(lambda r: findFile(path=r.path, row=r.row, files=propsDir), axis=1)\n",
    "\n",
    "# ignore tiles which don't have input variables created\n",
    "tindex = tindex[(~pd.isnull(tindex.OrthoFile))]\n",
    "\n",
    "#prioritize central tucson and work out from there\n",
    "tindex[\"centroid\"] = tindex.geometry.centroid\n",
    "central_tile = tindex[(tindex.path == \"W1004789\") & (tindex.row == \"W449850\")]\n",
    "central_point = central_tile.centroid.values[0]\n",
    "\n",
    "tindex[\"DistToCenter\"] = tindex.centroid.apply(lambda c: int(c.distance(central_point)))\n",
    "tindex.sort_values(by=\"DistToCenter\", inplace=True)\n",
    "\n",
    "#filter out files that are completed\n",
    "#tindex = tindex[pd.isnull(tindex[\"Done\"])]\n",
    "\n",
    "#tindex[\"Done\"]= tindex.apply(lambda r: findFile(path=r.path, row=r.row, directory=classifiedFiles_loc),axis=1)\n",
    "#toProcess = tindex[tindex.geometry.intersects(to_process.unary_union)].reset_index()                                 \n",
    "#classifyTiles(toProcess)\n",
    "#finished()\n",
    "#classifyTiles(tindex)\n",
    "#finished()\n",
    "\n",
    "print(\"\\nFINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\"Asphault\": \"Models/lightGBMBinaryAsphault_20210727.sav\",\n",
    "              \"Structure\": \"Models/lightGBMBinaryStructure_20210630.sav\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asphault\n",
      "\n",
      "\n",
      "Starting processing for 2 tiles\n",
      "\n",
      "Starting W1004789_W449850 @ 2021-07-28 16:41:20.906856\n",
      "Classified to M:\\PAG2019\\EPCExtent_30cm\\Orthos_Segmented_Classifiedv3\\W1004789_W449850_TrainingStackV3_AsphaultBinaryLGBNewishGBLM.tif. \n",
      "Classification took 0:00:31.318220\n",
      "Starting W989789_W439850 @ 2021-07-28 16:41:52.633658\n",
      "Classified to M:\\PAG2019\\EPCExtent_30cm\\Orthos_Segmented_Classifiedv3\\W989789_W439850_TrainingStackV3_AsphaultBinaryLGBNewishGBLM.tif. \n",
      "Classification took 0:00:30.865162\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for lcClass, model_loc in classifiers.items():\n",
    "    if lcClass != \"Asphault\":\n",
    "        continue\n",
    "    print(lcClass)\n",
    "    bestlgbm_model = pickle.load(open(model_loc, 'rb'))\n",
    "    \n",
    "    tt = tindex[((tindex.path == \"W989789\") & (tindex.row == \"W439850\")) |\n",
    "                ((tindex.path == \"W1004789\") & (tindex.row == \"W449850\"))]\n",
    "    t = classifyTiles(tt, forceStart=True, binaryClass=lcClass, overwrite=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%chime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting processing for 2 tiles\n",
      "\n",
      "Starting W1004789_W449850 @ 2021-06-16 13:46:36.417918\n",
      "Adding RGBNmean\n",
      "TO PREDICT SHAPE (25796241, 25)\n",
      "Starting W989789_W439850 @ 2021-06-16 13:47:55.627220\n",
      "Adding RGBNmean\n",
      "TO PREDICT SHAPE (25796241, 25)\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "tarray = t[1]\n",
    "    tkwargs = t[2]\n",
    "    print(tkwargs)\n",
    "\n",
    "    tkwargs.update(dtype=tarray.dtype)\n",
    "    with rio.open(\"test.tif\", \"w\", **tkwargs) as dst:\n",
    "        dst.write(tarray,1)\n",
    "    finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created M:\\PAG2019\\UrbanExtent_15cm\\Elevation_40cmNPS\\DSM40cm\\DSM40cm2019.vrt\n"
     ]
    }
   ],
   "source": [
    "buildVRT(\"../UrbanExtent_15cm/Elevation_40cmNPS/DSM40cm\", \"DSM40cm2019.vrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanupBinary(array, binaryClass=None):\n",
    "    if binaryClass == \"Structure\":\n",
    "        out[(out==9) & (bands[\"HAG\"]<5)] = 0 # if classified as structure, but less than 5 feet high, reclass to impervious\n",
    "        #out[(bands[\"REDness\"]>=35336) & (bands[\"GREENness\"]<=34307) & (bands[\"BLUEness\"]<=33409) & (lulc!=9) & (bands[\"DPR\"]<=3)] = 3 # good for red bare earth\n",
    "        out[(out==33023) & (bands[\"BLUEness\"]<38547) & (bands[\"NIRness\"]>23769)] = 0 # remove pools that aren't very blue AND does not have low NIRness value\n",
    "            \n",
    "        out[(bands[\"MSAVI\"]>=29556) & (bands[\"GREENness\"]>=34307) & (bands[\"RGBNmean\"]<=19273) ] = 0 # set very green veg with high index and low brightness to irrigated\n",
    "        \n",
    "        out = smoothStructures(out) # smooth structures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
